package com.github.dynodao;

import com.amazonaws.services.dynamodbv2.AmazonDynamoDB;
import com.github.dynodao.annotation.DynoDaoSchema;

import java.util.Spliterator;
import java.util.concurrent.ForkJoinPool;
import java.util.stream.Stream;

/**
 * A simplified DynamoDB data access object. This class is meant to be paired with the classes generated by <tt>DynoDaoProcessor</tt>.
 * <p>
 * In order to use DynoDao, you must first define a <i>schema</i> class. This is a POJO, aka <a href="https://en.wikipedia.org/wiki/JavaBeans">java-bean</a>,
 * annotated with {@link DynoDaoSchema @DynoDaoSchema}. This schema defined the structure of the DynamoDB table
 * that stores objects of that type, including indexes etc. For example, for a table named <tt>ITEMS</tt> with a single index, the
 * schema may look similar to:
 *
 * <pre>
 * <code>
 * {@literal @}DynoDaoSchema(tableName = "ITEMS")
 *  class Item {
 *     {@literal @}DynoDaoHashKey
 *      private String hashKey;
 *
 *     {@literal @}DynoDaoRangeKey
 *      private String rangeKey;
 *
 *     {@literal @}DynoDaoIndexRangeKey(lsiNames = "hash-key-lsi-range-key-index")
 *      private String lsiRangeKey;
 *
 *      // default constructor, getters and setters omitted
 *  }
 * </code>
 * </pre>
 *
 * Given this <tt>Item</tt>, the annotation processor will generate a <tt>ItemStagedDynamoBuilder</tt> class which is the entry
 * point to a fluent builder for interacting with {@link DynoDao} and DynamoDB.
 *
 * <h2><a name="read-operations">Reading Items</a></h2>
 * Most the supported read operations have a similar look and feel (with the exception of {@link DynoDao#get(DynoDaoScan, int)},
 * which is explained in further detail on the method documentation). To read items, you must create a new <em>staged builder</em>,
 * specify the index to operate on, filters, then pass the result to {@code get}.
 *
 * <pre>{@code
 *  // GetItem
 *  Stream<Item> item = dynoDao.get(new ItemStagedDynamoBuilder()
 *          .usingTable()
 *          .withHashKey("hashKeyValue")
 *          .withRangeKey("rangeKeyValue"));
 *
 *  // Query
 *  Stream<Item> items = dynoDao.get(new ItemStagedDynamoBuilder()
 *          .usingHashKeyLsiRangeKeyIndex()
 *          .withHashKey("hashKeyValue"));
 * }</pre>
 *
 * <h2><a name="serialization">Item Serialization</a></h2>
 * The provided DynamoDB client uses {@link com.amazonaws.services.dynamodbv2.model.AttributeValue AttributeValue}s, which
 * the {@code @DynoDaoSchema} class is converted to automatically. Not all type conversions are supported out of the box.
 * If your schema class contains some types which cannot be converted to {@code AttributeValue}, a compilation error will
 * be issued.
 *
 * @see <a href="https://github.com/twentylemon/dynodao">Project Page</a>
 */
public class DynoDao {

    private final AmazonDynamoDB amazonDynamoDb;

    /**
     * Sole constructor. Initializes the dynamo db client.
     * @param amazonDynamoDb the client this dao should use
     */
    public DynoDao(AmazonDynamoDB amazonDynamoDb) {
        this.amazonDynamoDb = amazonDynamoDb;
    }

    /**
     * Returns a stream containing the single document matching the full key of table, or an empty
     * stream if no such document exists.
     * @param load the load specification to use
     * @param <T> the type of document to get
     * @return a stream containing the document with the given key, or an empty stream if no such document exists
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_GetItem.html">GetItem API Documentation</a>
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/WorkingWithItems.html">Working with Items</a>
     */
    public <T> Stream<T> get(DynoDaoLoad<T> load) {
        return load.load(amazonDynamoDb);
    }

    /**
     * Returns a stream containing all of the documents matching the query.
     * @param query the query specification to use
     * @param <T> the type of documents to get
     * @return a stream of all of the documents matching the query
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Query.html">Query API Documentation</a>
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Query.html">Working with Queries</a>
     */
    public <T> Stream<T> get(DynoDaoQuery<T> query) {
        return query.query(amazonDynamoDb);
    }

    /**
     * Returns a stream containing all of the documents in the table.
     * @param scan the scan specification to use
     * @param <T> the type of documents to get
     * @return a stream containing all of the documents in the table
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html">Scan API Documentation</a>
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html">Working with Scans</a>
     */
    public <T> Stream<T> get(DynoDaoScan<T> scan) {
        return scan.scan(amazonDynamoDb);
    }

    /**
     * Returns a <b>parallel</b> stream containing all of the documents in the table. The returned stream <b>must</b>
     * remain parallel, though it is not enforced. The underlying stream will not return all items from the scan
     * if it is made sequential, either through {@link Stream#sequential()} or {@link Stream#iterator()}. Users
     * should also avoid manually accessing {@link Stream#spliterator()} unless they intend to split until {@link Spliterator#trySplit()}
     * returns <tt>null</tt>, and consume all spliterator instances (as a terminal Stream operation would).
     * <p>
     * As with all parallel streams, each split of the stream is evaluated on {@link ForkJoinPool#commonPool()}. The common pool
     * may not be the ideal place to run a parallel scan, especially if you use parallel streams in several places. It is possible
     * to specify a custom {@link ForkJoinPool} to run on with the following:
     * <pre>{@code
     *     ForkJoinPool pool = new ForkJoinPool(numberOfThreads);
     *     Stream<Item> items = dynoDao.get(parallelScanSpec, numberOfThreads);
     *     // runs in `pool` and blocks until the operation is complete
     *     Map<String, Long> countsByName = pool.submit(() -> items.collect(groupingBy(Item::getName, counting()))).join();
     * }</pre>
     * If you use your own thread pool, prefer to use the same number of threads as scan segments. Additional threads
     * won't be used, and using less may cause some segments to be <i>starved</i>, causing the scan to take long as
     * it waits for other segments to complete.
     * @param parallelScan the scan specification to use
     * @param totalParallelScanSegments the number of segments to use in the scan
     * @param <T> the type of documents to get
     * @return a stream containing all of the documents in the table
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/APIReference/API_Scan.html">Scan API Documentation</a>
     * @see <a href="https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/Scan.html#Scan.ParallelScan">Working with Parallel Scans</a>
     */
    public <T> Stream<T> get(DynoDaoScan<T> parallelScan, int totalParallelScanSegments) {
        return parallelScan.parallelScan(amazonDynamoDb, totalParallelScanSegments);
    }

}
